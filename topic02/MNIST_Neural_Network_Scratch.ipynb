{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dwi2EDC_bHY"
      },
      "source": [
        "Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIaSVSr_PUG",
        "outputId": "4c07f5b1-d3dd-420a-b40c-72f88e2301bb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One-hot encode labels [0, 1, 0 , 0, 0 ...., 0]\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "OuTdodZvTIEr",
        "outputId": "fd6ad574-1786-4f87-c2dc-2185aa1c24a8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Choose a sample index to visualize\n",
        "sample_index = 0\n",
        "\n",
        "# Reshape the sample to its original shape (28x28) for visualization\n",
        "sample_image = X_train[sample_index].reshape(28, 28)\n",
        "\n",
        "# Visualize the sample\n",
        "plt.imshow(sample_image, cmap='gray')\n",
        "plt.title(f'Label: {y_train[sample_index]}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLu6tu7_jct"
      },
      "source": [
        "Model Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnFC9iX_kEk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Model:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    self.W1, self.W2 = self.initialize_weights(input_size, hidden_size, output_size)\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    # Activation function\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  def sigmoid_derivative(self, x):\n",
        "    # Derivative of the sigmoid function\n",
        "    return x * (1 - x)\n",
        "\n",
        "  def initialize_weights(self, input_size, hidden_size, output_size):\n",
        "    # Initialize weights randomly with a mean of 0\n",
        "    W1 = np.random.randn(input_size, hidden_size)\n",
        "    W2 = np.random.randn(hidden_size, output_size)\n",
        "    return W1, W2\n",
        "\n",
        "  def forward_propagate(self, X):\n",
        "    # Feed forward input X through a network\n",
        "    H = self.sigmoid(np.dot(X, self.W1))\n",
        "    Y = self.sigmoid(np.dot(H, self.W2))\n",
        "    return H, Y\n",
        "\n",
        "\n",
        "  def back_propagate(self, X, H, Y, y_true):\n",
        "    # Back propagate errors and update weights\n",
        "    m = X.shape[0]\n",
        "    error = Y - y_true\n",
        "    dW2 = (1/m) * np.dot(H.T, error)\n",
        "    dH = np.dot(error, self.W2.T) * self.sigmoid_derivative(H)\n",
        "    dW1 = (1/m) * np.dot(X.T, dH)\n",
        "    return dW1, dW2\n",
        "\n",
        "  def update_weights(self, dW1, dW2, learning_rate):\n",
        "    # Update weights using gradient descent\n",
        "    self.W1 -= learning_rate * dW1\n",
        "    self.W2 -= learning_rate * dW2\n",
        "\n",
        "  def cross_entropy_loss(self, Y_pred, Y_true):\n",
        "    # Calculate cross-entropy loss\n",
        "    m = Y_true.shape[0]\n",
        "    loss = -1/m * np.sum(Y_true * np.log(Y_pred) + (1 - Y_true) * np.log(1 - Y_pred))\n",
        "    return loss\n",
        "\n",
        "  def optimize(self, X, y_true, num_epochs, learning_rate, batch_size):\n",
        "    for epoch in range(num_epochs):\n",
        "      # Shuffle data\n",
        "      shuffled_indices = np.random.permutation(X.shape[0])\n",
        "      X = X[shuffled_indices]\n",
        "      y_true = y_true[shuffled_indices]\n",
        "\n",
        "      # Split data into mini-batches\n",
        "      num_batches = X.shape[0] // batch_size\n",
        "      for batch_index in range(num_batches):\n",
        "        start_index = batch_index * batch_size\n",
        "        end_index = start_index + batch_size\n",
        "        X_batch = X[start_index:end_index]\n",
        "        y_batch = y_true[start_index:end_index]\n",
        "\n",
        "        # Feed forward\n",
        "        H, Y = self.forward_propagate(X_batch)\n",
        "\n",
        "        predictions = np.argmax(Y, axis=1)\n",
        "        loss = self.cross_entropy_loss(Y, y_batch)\n",
        "        accuracy = np.mean(predictions == np.argmax(y_batch, axis=1))\n",
        "\n",
        "        # Back propagate\n",
        "        dW1, dW2 = self.back_propagate(X_batch, H, Y, y_batch)\n",
        "\n",
        "        # Update weights\n",
        "        self.update_weights(dW1, dW2, learning_rate)\n",
        "      print('Epoch: {} - Loss: {} - Accuracy: {}'.format(epoch, loss, accuracy))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvVSXzQ9_sqp",
        "outputId": "edc6311b-d49f-480c-e8fd-02a8c53394a6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create model\n",
        "model = Model(input_size=784, hidden_size=64, output_size=10)\n",
        "\n",
        "# Train model\n",
        "model.optimize(X_train, y_train, num_epochs=10, learning_rate=0.01, batch_size=64)\n",
        "\n",
        "# Evaluate model\n",
        "H, Y = model.forward_propagate(X_test)\n",
        "predictions = np.argmax(Y, axis=1)\n",
        "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
